{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c ghi v√†o PostgreSQL!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import psycopg2\n",
    "\n",
    "# K·∫øt n·ªëi ƒë·∫øn PostgreSQL\n",
    "DB_NAME = \"postgres\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"minh0985362932\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD,\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # ƒê·ªçc file JSON\n",
    "    with open(\"Data/chunked_df.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Ch√®n d·ªØ li·ªáu v√†o b·∫£ng PostgreSQL\n",
    "    for entry in data:\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO articles_about_health_care (id, id_baiviet, content) \n",
    "            VALUES (%s, %s, %s)\n",
    "            ON CONFLICT (id) DO NOTHING;  -- Tr√°nh l·ªói tr√πng ID\n",
    "        \"\"\", (entry[\"id\"], entry[\"id_baiviet\"], entry[\"content\"]))\n",
    "\n",
    "    # L∆∞u thay ƒë·ªïi\n",
    "    conn.commit()\n",
    "    print(\"D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c ghi v√†o PostgreSQL!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"L·ªói:\", e)\n",
    "\n",
    "finally:\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if conn:\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c ghi v√†o PostgreSQL!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # K·∫øt n·ªëi ƒë·∫øn PostgreSQL\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD,\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # ƒê·ªçc file JSON\n",
    "    with open(\"Data/classification_query.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Ghi d·ªØ li·ªáu v√†o PostgreSQL\n",
    "    for entry in data:\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO embeddings_query (texts, labels, embeddings)\n",
    "            VALUES (%s, %s, %s);\n",
    "        \"\"\", (entry[\"texts\"], entry[\"labels\"], json.dumps(entry[\"embeddings\"])))  # Chuy·ªÉn embeddings th√†nh JSON\n",
    "\n",
    "    # L∆∞u thay ƒë·ªïi\n",
    "    conn.commit()\n",
    "    print(\"D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c ghi v√†o PostgreSQL!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"L·ªói:\", e)\n",
    "\n",
    "finally:\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing & TF Processing:   7%|‚ñã         | 20957/317023 [03:19<41:23, 119.19it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è B·ªè qua ID longchau_baiviet_article_data18110_0 (n·ªôi dung tr·ªëng)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing & TF Processing:  20%|‚ñà‚ñà        | 63458/317023 [10:07<38:57, 108.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è B·ªè qua ID longchau_baiviet_article_data14035_6 (n·ªôi dung tr·ªëng)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing & TF Processing:  28%|‚ñà‚ñà‚ñä       | 89134/317023 [14:12<37:11, 102.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è B·ªè qua ID vinmec_article_data26334_3 (n·ªôi dung tr·ªëng)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing & TF Processing:  41%|‚ñà‚ñà‚ñà‚ñà      | 130495/317023 [20:39<23:32, 132.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è B·ªè qua ID vinmec_article_data29491_8 (n·ªôi dung tr·ªëng)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing & TF Processing:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 241305/317023 [38:14<12:14, 103.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è B·ªè qua ID longchau_baiviet_article_data28303_6 (n·ªôi dung tr·ªëng)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing & TF Processing:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 251996/317023 [39:58<09:25, 115.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è B·ªè qua ID vinmec_article_data26316_1 (n·ªôi dung tr·ªëng)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing & TF Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 317023/317023 [50:18<00:00, 105.03it/s]\n",
      "Saving to DB: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 317017/317017 [00:11<00:00, 28013.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ T·∫ßn su·∫•t t·ª´ (TF) ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o PostgreSQL!\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import json\n",
    "from collections import Counter\n",
    "from rank_bm25 import BM25Okapi\n",
    "from pyvi import ViTokenizer\n",
    "from tqdm import tqdm  # Import tqdm ƒë·ªÉ hi·ªÉn th·ªã progress bar\n",
    "\n",
    "# ƒê·ªçc danh s√°ch stopwords t·ª´ file\n",
    "def load_stopwords(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        stopwords = set(f.read().splitlines())\n",
    "    return stopwords\n",
    "\n",
    "stopwords = load_stopwords(\"vietnamese-stopwords-dash.txt\")  \n",
    "\n",
    "# K·∫øt n·ªëi PostgreSQL\n",
    "DB_NAME = \"postgres\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"minh0985362932\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# L·∫•y b√†i vi·∫øt t·ª´ database\n",
    "cursor.execute(\"SELECT id, content FROM articles_about_health_care\")\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "if not rows:\n",
    "    print(\"‚ùå Kh√¥ng c√≥ b√†i vi·∫øt n√†o trong database!\")\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    exit()\n",
    "\n",
    "# X·ª≠ l√Ω TF cho c·∫£ lowercase & uppercase\n",
    "tf_corpus_lower = []\n",
    "tf_corpus_upper = []\n",
    "id_list = []\n",
    "\n",
    "print(\"üîÑ ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...\")\n",
    "for id_baiviet, content in tqdm(rows, desc=\"Tokenizing & TF Processing\"):\n",
    "    if not content or content.strip() == \"\":\n",
    "        print(f\"‚ö†Ô∏è B·ªè qua ID {id_baiviet} (n·ªôi dung tr·ªëng)\")\n",
    "        continue\n",
    "\n",
    "    # Tokenize v·ªõi lowercase\n",
    "    tokenized_text_lower = ViTokenizer.tokenize(content.lower()).split()\n",
    "    tokenized_text_lower = [word for word in tokenized_text_lower if word not in stopwords]\n",
    "    \n",
    "    # Tokenize v·ªõi nguy√™n g·ªëc\n",
    "    tokenized_text_upper = ViTokenizer.tokenize(content).split()\n",
    "    tokenized_text_upper = [word for word in tokenized_text_upper if word not in stopwords]\n",
    "\n",
    "    if not tokenized_text_lower or not tokenized_text_upper:\n",
    "        print(f\"‚ö†Ô∏è B·ªè qua ID {id_baiviet} (kh√¥ng c√≤n t·ª´ h·ª£p l·ªá)\")\n",
    "        continue\n",
    "\n",
    "    # T√≠nh t·∫ßn su·∫•t t·ª´ (TF)\n",
    "    tf_lower = dict(Counter(tokenized_text_lower))\n",
    "    tf_upper = dict(Counter(tokenized_text_upper))\n",
    "\n",
    "    tf_corpus_lower.append(tf_lower)\n",
    "    tf_corpus_upper.append(tf_upper)\n",
    "    id_list.append(id_baiviet)\n",
    "\n",
    "if not tf_corpus_lower or not tf_corpus_upper:\n",
    "    print(\"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá ƒë·ªÉ l∆∞u TF!\")\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    exit()\n",
    "\n",
    "# L∆∞u TF v√†o database v·ªõi tqdm\n",
    "data_to_insert = []\n",
    "for idx, id_baiviet in tqdm(enumerate(id_list), total=len(id_list), desc=\"Saving to DB\"):\n",
    "    tf_json_lower = json.dumps(tf_corpus_lower[idx])\n",
    "    tf_json_upper = json.dumps(tf_corpus_upper[idx])\n",
    "    data_to_insert.append((id_baiviet, tf_json_lower, tf_json_upper))\n",
    "\n",
    "cursor.executemany(\"\"\"\n",
    "    INSERT INTO word_frequency_health_paragraphs (id, tf_lower, tf_upper)\n",
    "    VALUES (%s, %s, %s)\n",
    "    ON CONFLICT (id) DO UPDATE \n",
    "    SET tf_lower = EXCLUDED.tf_lower,\n",
    "        tf_upper = EXCLUDED.tf_upper;\n",
    "\"\"\", data_to_insert)\n",
    "\n",
    "conn.commit()\n",
    "print(\"‚úÖ T·∫ßn su·∫•t t·ª´ (TF) ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o PostgreSQL!\")\n",
    "\n",
    "# ƒê√≥ng k·∫øt n·ªëi\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import json\n",
    "from collections import Counter\n",
    "from rank_bm25 import BM25Okapi\n",
    "from pyvi import ViTokenizer\n",
    "from tqdm import tqdm  # Import tqdm ƒë·ªÉ hi·ªÉn th·ªã progress bar\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load API key t·ª´ .env\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    dbname=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT id, tf_lower FROM word_frequency_health_paragraphs\")\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "tokenized_corpus = []\n",
    "id_list = []\n",
    "\n",
    "for id_baiviet, tf_json in rows:\n",
    "    if isinstance(tf_json, dict):  # N·∫øu ƒë√£ l√† dict, kh√¥ng c·∫ßn json.loads\n",
    "        tf = tf_json\n",
    "    elif isinstance(tf_json, str):  # N·∫øu l√† chu·ªói, parse JSON\n",
    "        tf = json.loads(tf_json)\n",
    "    elif tf_json is None:  # N·∫øu l√† NULL trong PostgreSQL\n",
    "        tf = {}\n",
    "    else:\n",
    "        raise TypeError(f\"‚ùå D·ªØ li·ªáu kh√¥ng h·ª£p l·ªá cho ID {id_baiviet}: {type(tf_json)}\")\n",
    "    \n",
    "    tokenized_corpus.append(list(tf.keys()))\n",
    "    id_list.append(id_baiviet)\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)  # T·∫°o BM25 v·ªõi d·ªØ li·ªáu m·ªõi\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: vinmec_article_data6215_10, Score: 11.441529838277395\n",
      "ID: longchau_baiviet_article_data30557_3, Score: 11.06425292496572\n",
      "ID: vinmec_article_data17055_5, Score: 10.69457584952342\n",
      "ID: longchau_baiviet_article_data18332_3, Score: 10.544272380072682\n",
      "ID: vinmec_article_data29262_2, Score: 10.221624573949864\n",
      "ID: longchau_baiviet_article_data21439_2, Score: 10.18636975340763\n",
      "ID: longchau_mevabe_article_data2464_2, Score: 9.983057711664141\n",
      "ID: longchau_baiviet_article_data211_2, Score: 9.851965977218667\n",
      "ID: longchau_baiviet_article_data12729_0, Score: 9.846674404571841\n",
      "ID: longchau_baiviet_article_data36220_1, Score: 9.724272460869829\n",
      "\n",
      "üì∞ B√†i vi·∫øt li√™n quan (ID: vinmec_article_data6215_10):\n",
      "11. ƒê·∫≠u ƒëen Trong t·∫•t c·∫£ c√°c lo·∫°i ƒë·∫≠u th√¨ ƒë·∫≠u ƒëen ƒë∆∞·ª£c coi l√† m·ªôt trong nh·ªØng lo·∫°i ƒë·∫≠u l√†nh m·∫°nh nh·∫•t. ƒê·∫≠u ƒëen c√≤n ƒë∆∞·ª£c g·ªçi l√† ƒë·∫≠u r√πa v·ªõi h√†m l∆∞·ª£ng ch·∫•t ch·ªëng oxy h√≥a cao c√≥ t√°c d·ª•ng gi·∫£m nguy c∆° ung th∆∞ v√∫ v√† c√°c lo·∫°i ung th∆∞ kh√°c. ƒê·∫≠u ƒëen c≈©ng l√† m·ªôt ngu·ªìn m·∫°nh m·∫Ω c·ªßa ergothioneine, m·ªôt axit amin b·∫£o v·ªá DNA c·ªßa b·∫°n.\n",
      "\n",
      "üì∞ B√†i vi·∫øt li√™n quan (ID: longchau_baiviet_article_data30557_3):\n",
      "ƒê·∫≠u xanh ho·∫∑c ƒë·∫≠u ƒëen Theo ƒê√¥ng y, ƒë·∫≠u xanh c√≥ v·ªã ng·ªçt, t√≠nh h√†n, kh√¥ng ƒë·ªôc, b·ªï nguy√™n kh√≠, thanh nhi·ªát m√°t gan, gi·∫£i ƒë·ªôc, c√≤n ƒë·∫≠u ƒëen l·∫°i mang v·ªã ng·ªçt nh·∫°t, t√≠nh m√°t, c√≥ t√°c d·ª•ng b·ªï huy·∫øt, b·ªï can th·∫≠n, gi·∫£i phong nhi·ªát, gi·∫£i ƒë·ªôc, h·∫° kh√≠, l·ª£i ti·ªÉu. Vi·ªác d√πng n∆∞·ªõc ƒë·∫≠u xanh ho·∫∑c ƒë·∫≠u ƒëen ƒë·ªÉ gi·∫£i bia r∆∞·ª£u c≈©ng l√† m·ªôt c√°ch l√†m hi·ªáu qu·∫£ cho ng∆∞·ªùi say x·ªân.\n",
      "\n",
      "üì∞ B√†i vi·∫øt li√™n quan (ID: vinmec_article_data17055_5):\n",
      "6. C√°c lo·∫°i ƒë·∫≠u v√† c√¢y h·ªç ƒë·∫≠u ƒê√¢y l√† nh·ªØng l·ª±a ch·ªçn th√≠ch h·ª£p cho ng∆∞·ªùi ƒÉn chay. Ch√∫ng kh√¥ng ch·ªâ √≠t b√©o, nhi·ªÅu ch·∫•t x∆°, m√† c√≤n gi√∫p t·∫ßm nh√¨n c·ªßa b·∫°n s·∫Øc n√©t h∆°n v√†o ban ƒë√™m, ƒë·ªìng th·ªùi l√†m ch·∫≠m qu√° tr√¨nh tho√°i h√≥a ƒëi·ªÉm v√†ng. ƒê·∫≠u ƒëen ch·ª©a nhi·ªÅu k·∫Ωm - kho√°ng ch·∫•t r·∫•t c·∫ßn thi·∫øt cho s·ª©c kh·ªèe c·ªßa v√µng m·∫°c, gi√∫p duy tr√¨ c√°c m·∫°ch m√°u ph·ª•c v·ª• nh√£n c·∫ßu. ƒê·∫≠u ƒëen c√≤n c√≥ t√°c d·ª•ng ngƒÉn ng·ª´a m·∫•t th·ªã l·ª±c c≈©ng nh∆∞ ƒë·ª•c th·ªßy tinh th·ªÉ. Ngo√†i ra, ƒë·∫≠u xanh, ƒë·∫≠u th·∫≠n (ƒë·∫≠u ƒë·ªè t√¢y) v√† ƒë·∫≠u lƒÉng c≈©ng ch·ª©a kh√° nhi·ªÅu k·∫Ωm. M·ªôt lon ƒë·∫≠u n∆∞·ªõng ch√≠nh l√† ƒë·ªì ƒÉn t·ªët cho m·∫Øt c·ªßa b·∫°n.\n",
      "\n",
      "üì∞ B√†i vi·∫øt li√™n quan (ID: longchau_baiviet_article_data18332_3):\n",
      "ƒê·∫≠u n√†nh ƒê·∫≠u n√†nh l√† th·ª±c ph·∫©m ƒë∆∞·ª£c nhi·ªÅu ch·ªã em ph·ª• n·ªØ ƒë√°nh gi√° l√† c√≥ kh·∫£ nƒÉng k√≠ch th√≠ch tƒÉng v√≤ng 1 nhanh ch√≥ng do ch·ª©a nhi·ªÅu Phytoestrogens - hormone k√≠ch th√≠ch s·ª± ph√°t tri·ªÉn c·ªßa m√¥ ng·ª±c. ƒê·∫∑c bi·ªát, ch·∫•t Isoflavone c√≥ ·ªü b√™n trong ƒë·∫≠u n√†nh c√≥ t√°c d·ª•ng gi√∫p ch·ªã em ch·ªëng l·∫°i ƒë∆∞·ª£c g·ªëc t·ª± do v√† c√°c t·∫ø b√†o g√¢y ra b·ªánh ung th∆∞ v√∫. Do ƒë√≥, ch·ªã em n√™n ƒÉn c√°c m√≥n ƒÉn ƒë∆∞·ª£c ch·∫ø bi·∫øn t·ª´ ƒë·∫≠u n√†nh th∆∞·ªùng xuy√™n nh∆∞ ƒë·∫≠u h≈©, t√†o ph·ªõ, h·∫°t ƒë·∫≠u s·∫•y,‚Ä¶ ƒë·ªÉ v·ª´a tƒÉng size v√≤ng 1 v·ª´a b·∫£o v·ªá cho s·ª©c kh·ªèe. Ngo√†i ƒë·∫≠u n√†nh, ch·ªã em c≈©ng c√≥ th·ªÉ b·ªï sung th√™m cho c∆° th·ªÉ m·ªôt s·ªë lo·∫°i th·ª±c ph·∫©m kh√°c nh∆∞ ƒë·∫≠u xanh, ƒë·∫≠u ƒëen v√†o ch·∫ø ƒë·ªô ƒÉn h√†ng ng√†y ƒë·ªÉ ng·ª±c to h∆°n.\n"
     ]
    }
   ],
   "source": [
    "from pyvi import ViTokenizer\n",
    "\n",
    "query = \"ƒë·∫≠u ƒëen c√≥ t√°c d·ª•ng g√¨ cho s·ª©c kh·ªèe\"  # C√¢u truy v·∫•n\n",
    "tokenized_query = ViTokenizer.tokenize(query.lower()).split()  # Tokenize & lowercase\n",
    "\n",
    "scores = bm25.get_scores(tokenized_query)  # T√≠nh ƒëi·ªÉm BM25 cho m·ªói vƒÉn b·∫£n\n",
    "\n",
    "# S·∫Øp x·∫øp k·∫øt qu·∫£ theo ƒëi·ªÉm s·ªë t·ª´ cao ƒë·∫øn th·∫•p\n",
    "sorted_results = sorted(zip(id_list, scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# In k·∫øt qu·∫£\n",
    "for doc_id, score in sorted_results[:10]:  # L·∫•y top 10 k·∫øt qu·∫£\n",
    "    print(f\"ID: {doc_id}, Score: {score}\")\n",
    "conn = psycopg2.connect(\n",
    "    dbname=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "top_ids = [doc_id for doc_id, _ in sorted_results[:4]]  # L·∫•y 3 ID c√≥ ƒëi·ªÉm cao nh·∫•t\n",
    "context = \"\"\n",
    "for i,doc_id in enumerate(top_ids):\n",
    "    cursor.execute(\"SELECT content FROM articles_about_health_care WHERE id = %s\", (doc_id,))\n",
    "    result = cursor.fetchone()\n",
    "    \n",
    "    if result:\n",
    "        print(f\"\\nüì∞ B√†i vi·∫øt li√™n quan (ID: {doc_id}):\")\n",
    "        text = result[0].replace(\"\\n\", \" \").replace(\"  \", \" \")\n",
    "        print(text)\n",
    "        text = f'''ƒêo·∫°n {i}: \"{text}\"\\n'''\n",
    "        context += text\n",
    "    else:\n",
    "        print(f\"‚ùå Kh√¥ng t√¨m th·∫•y b√†i vi·∫øt cho ID: {doc_id}\")\n",
    "\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 41 key-value pairs and 338 tensors from local_model/Vi-Qwen2-1.5B-RAG.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = qwen2\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Vi Qwen2 1.5B RAG\n",
      "llama_model_loader: - kv   3:                       general.organization str              = AITeamVN\n",
      "llama_model_loader: - kv   4:                           general.finetune str              = RAG\n",
      "llama_model_loader: - kv   5:                           general.basename str              = Vi-Qwen2\n",
      "llama_model_loader: - kv   6:                         general.size_label str              = 1.5B\n",
      "llama_model_loader: - kv   7:                            general.license str              = apache-2.0\n",
      "llama_model_loader: - kv   8:                   general.base_model.count u32              = 1\n",
      "llama_model_loader: - kv   9:                  general.base_model.0.name str              = Qwen2 7B Instruct\n",
      "llama_model_loader: - kv  10:          general.base_model.0.organization str              = Qwen\n",
      "llama_model_loader: - kv  11:              general.base_model.0.repo_url str              = https://huggingface.co/Qwen/Qwen2-7B-...\n",
      "llama_model_loader: - kv  12:                               general.tags arr[str,3]       = [\"retrieval-augmented-generation\", \"t...\n",
      "llama_model_loader: - kv  13:                          general.languages arr[str,1]       = [\"vi\"]\n",
      "llama_model_loader: - kv  14:                          qwen2.block_count u32              = 28\n",
      "llama_model_loader: - kv  15:                       qwen2.context_length u32              = 32768\n",
      "llama_model_loader: - kv  16:                     qwen2.embedding_length u32              = 1536\n",
      "llama_model_loader: - kv  17:                  qwen2.feed_forward_length u32              = 8960\n",
      "llama_model_loader: - kv  18:                 qwen2.attention.head_count u32              = 12\n",
      "llama_model_loader: - kv  19:              qwen2.attention.head_count_kv u32              = 2\n",
      "llama_model_loader: - kv  20:                       qwen2.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  21:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  22:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  23:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  24:                         tokenizer.ggml.pre str              = qwen2\n",
      "llama_model_loader: - kv  25:                      tokenizer.ggml.tokens arr[str,151936]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  26:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  27:                      tokenizer.ggml.merges arr[str,151387]  = [\"ƒ† ƒ†\", \"ƒ†ƒ† ƒ†ƒ†\", \"i n\", \"ƒ† t\",...\n",
      "llama_model_loader: - kv  28:                tokenizer.ggml.eos_token_id u32              = 151645\n",
      "llama_model_loader: - kv  29:            tokenizer.ggml.padding_token_id u32              = 151643\n",
      "llama_model_loader: - kv  30:                tokenizer.ggml.bos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  31:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  32:                    tokenizer.chat_template str              = {% set system_message = 'You are a he...\n",
      "llama_model_loader: - kv  33:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  34:                                general.url str              = https://huggingface.co/mradermacher/V...\n",
      "llama_model_loader: - kv  35:              mradermacher.quantize_version str              = 2\n",
      "llama_model_loader: - kv  36:                  mradermacher.quantized_by str              = mradermacher\n",
      "llama_model_loader: - kv  37:                  mradermacher.quantized_at str              = 2024-10-10T08:25:35+02:00\n",
      "llama_model_loader: - kv  38:                  mradermacher.quantized_on str              = db3\n",
      "llama_model_loader: - kv  39:                         general.source.url str              = https://huggingface.co/AITeamVN/Vi-Qw...\n",
      "llama_model_loader: - kv  40:                  mradermacher.convert_type str              = hf\n",
      "llama_model_loader: - type  f32:  141 tensors\n",
      "llama_model_loader: - type q4_K:  168 tensors\n",
      "llama_model_loader: - type q6_K:   29 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 934.69 MiB (5.08 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 151661 '<|fim_suffix|>' is not marked as EOG\n",
      "load: control token: 151649 '<|box_end|>' is not marked as EOG\n",
      "load: control token: 151647 '<|object_ref_end|>' is not marked as EOG\n",
      "load: control token: 151654 '<|vision_pad|>' is not marked as EOG\n",
      "load: control token: 151659 '<|fim_prefix|>' is not marked as EOG\n",
      "load: control token: 151648 '<|box_start|>' is not marked as EOG\n",
      "load: control token: 151644 '<|im_start|>' is not marked as EOG\n",
      "load: control token: 151646 '<|object_ref_start|>' is not marked as EOG\n",
      "load: control token: 151650 '<|quad_start|>' is not marked as EOG\n",
      "load: control token: 151651 '<|quad_end|>' is not marked as EOG\n",
      "load: control token: 151652 '<|vision_start|>' is not marked as EOG\n",
      "load: control token: 151653 '<|vision_end|>' is not marked as EOG\n",
      "load: control token: 151655 '<|image_pad|>' is not marked as EOG\n",
      "load: control token: 151656 '<|video_pad|>' is not marked as EOG\n",
      "load: control token: 151660 '<|fim_middle|>' is not marked as EOG\n",
      "load: special tokens cache size = 22\n",
      "load: token to piece cache size = 0.9310 MB\n",
      "print_info: arch             = qwen2\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 1536\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 12\n",
      "print_info: n_head_kv        = 2\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 6\n",
      "print_info: n_embd_k_gqa     = 256\n",
      "print_info: n_embd_v_gqa     = 256\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-06\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8960\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 2\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 1000000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 1.5B\n",
      "print_info: model params     = 1.54 B\n",
      "print_info: general.name     = Vi Qwen2 1.5B RAG\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 151936\n",
      "print_info: n_merges         = 151387\n",
      "print_info: BOS token        = 151643 '<|endoftext|>'\n",
      "print_info: EOS token        = 151645 '<|im_end|>'\n",
      "print_info: EOT token        = 151645 '<|im_end|>'\n",
      "print_info: PAD token        = 151643 '<|endoftext|>'\n",
      "print_info: LF token         = 198 'ƒä'\n",
      "print_info: FIM PRE token    = 151659 '<|fim_prefix|>'\n",
      "print_info: FIM SUF token    = 151661 '<|fim_suffix|>'\n",
      "print_info: FIM MID token    = 151660 '<|fim_middle|>'\n",
      "print_info: FIM PAD token    = 151662 '<|fim_pad|>'\n",
      "print_info: FIM REP token    = 151663 '<|repo_name|>'\n",
      "print_info: FIM SEP token    = 151664 '<|file_sep|>'\n",
      "print_info: EOG token        = 151643 '<|endoftext|>'\n",
      "print_info: EOG token        = 151645 '<|im_end|>'\n",
      "print_info: EOG token        = 151662 '<|fim_pad|>'\n",
      "print_info: EOG token        = 151663 '<|repo_name|>'\n",
      "print_info: EOG token        = 151664 '<|file_sep|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU\n",
      "load_tensors: layer   1 assigned to device CPU\n",
      "load_tensors: layer   2 assigned to device CPU\n",
      "load_tensors: layer   3 assigned to device CPU\n",
      "load_tensors: layer   4 assigned to device CPU\n",
      "load_tensors: layer   5 assigned to device CPU\n",
      "load_tensors: layer   6 assigned to device CPU\n",
      "load_tensors: layer   7 assigned to device CPU\n",
      "load_tensors: layer   8 assigned to device CPU\n",
      "load_tensors: layer   9 assigned to device CPU\n",
      "load_tensors: layer  10 assigned to device CPU\n",
      "load_tensors: layer  11 assigned to device CPU\n",
      "load_tensors: layer  12 assigned to device CPU\n",
      "load_tensors: layer  13 assigned to device CPU\n",
      "load_tensors: layer  14 assigned to device CPU\n",
      "load_tensors: layer  15 assigned to device CPU\n",
      "load_tensors: layer  16 assigned to device CPU\n",
      "load_tensors: layer  17 assigned to device CPU\n",
      "load_tensors: layer  18 assigned to device CPU\n",
      "load_tensors: layer  19 assigned to device CPU\n",
      "load_tensors: layer  20 assigned to device CPU\n",
      "load_tensors: layer  21 assigned to device CPU\n",
      "load_tensors: layer  22 assigned to device CPU\n",
      "load_tensors: layer  23 assigned to device CPU\n",
      "load_tensors: layer  24 assigned to device CPU\n",
      "load_tensors: layer  25 assigned to device CPU\n",
      "load_tensors: layer  26 assigned to device CPU\n",
      "load_tensors: layer  27 assigned to device CPU\n",
      "load_tensors: layer  28 assigned to device CPU\n",
      "load_tensors: tensor 'token_embd.weight' (q6_K) (and 338 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors:   CPU_Mapped model buffer size =   934.69 MiB\n",
      "................................................................................\n",
      "llama_init_from_model: n_seq_max     = 1\n",
      "llama_init_from_model: n_ctx         = 8192\n",
      "llama_init_from_model: n_ctx_per_seq = 8192\n",
      "llama_init_from_model: n_batch       = 512\n",
      "llama_init_from_model: n_ubatch      = 512\n",
      "llama_init_from_model: flash_attn    = 0\n",
      "llama_init_from_model: freq_base     = 1000000.0\n",
      "llama_init_from_model: freq_scale    = 1\n",
      "llama_init_from_model: n_ctx_per_seq (8192) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init: kv_size = 8192, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 256, n_embd_v_gqa = 256\n",
      "llama_kv_cache_init:        CPU KV buffer size =   224.00 MiB\n",
      "llama_init_from_model: KV self size  =  224.00 MiB, K (f16):  112.00 MiB, V (f16):  112.00 MiB\n",
      "llama_init_from_model:        CPU  output buffer size =     0.58 MiB\n",
      "llama_init_from_model:        CPU compute buffer size =   302.75 MiB\n",
      "llama_init_from_model: graph nodes  = 986\n",
      "llama_init_from_model: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | AVX512 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'mradermacher.convert_type': 'hf', 'general.name': 'Vi Qwen2 1.5B RAG', 'general.architecture': 'qwen2', 'general.type': 'model', 'general.organization': 'AITeamVN', 'general.basename': 'Vi-Qwen2', 'general.finetune': 'RAG', 'mradermacher.quantized_on': 'db3', 'general.size_label': '1.5B', 'general.license': 'apache-2.0', 'general.base_model.count': '1', 'general.base_model.0.name': 'Qwen2 7B Instruct', 'general.base_model.0.organization': 'Qwen', 'general.base_model.0.repo_url': 'https://huggingface.co/Qwen/Qwen2-7B-Instruct', 'qwen2.block_count': '28', 'qwen2.context_length': '32768', 'general.url': 'https://huggingface.co/mradermacher/Vi-Qwen2-1.5B-RAG-GGUF', 'qwen2.embedding_length': '1536', 'general.source.url': 'https://huggingface.co/AITeamVN/Vi-Qwen2-1.5B-RAG', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '151643', 'qwen2.feed_forward_length': '8960', 'qwen2.attention.head_count': '12', 'qwen2.attention.head_count_kv': '2', 'tokenizer.ggml.padding_token_id': '151643', 'qwen2.rope.freq_base': '1000000.000000', 'qwen2.attention.layer_norm_rms_epsilon': '0.000001', 'tokenizer.ggml.eos_token_id': '151645', 'general.file_type': '15', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.pre': 'qwen2', 'tokenizer.ggml.add_bos_token': 'false', 'tokenizer.chat_template': \"{% set system_message = 'You are a helpful assistant.' %}{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% endif %}{% if system_message is defined %}{{ '<|im_start|>system\\n' + system_message + '<|im_end|>\\n' }}{% endif %}{% for message in loop_messages %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<|im_start|>user\\n' + content + '<|im_end|>\\n<|im_start|>assistant\\n' }}{% elif message['role'] == 'assistant' %}{{ content + '<|im_end|>' + '\\n' }}{% endif %}{% endfor %}\", 'mradermacher.quantize_version': '2', 'mradermacher.quantized_by': 'mradermacher', 'mradermacher.quantized_at': '2024-10-10T08:25:35+02:00'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% set system_message = 'You are a helpful assistant.' %}{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% endif %}{% if system_message is defined %}{{ '<|im_start|>system\n",
      "' + system_message + '<|im_end|>\n",
      "' }}{% endif %}{% for message in loop_messages %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<|im_start|>user\n",
      "' + content + '<|im_end|>\n",
      "<|im_start|>assistant\n",
      "' }}{% elif message['role'] == 'assistant' %}{{ content + '<|im_end|>' + '\n",
      "' }}{% endif %}{% endfor %}\n",
      "Using chat eos_token: <|im_end|>\n",
      "Using chat bos_token: <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama(model_path=\"local_model/Vi-Qwen2-1.5B-RAG.Q4_K_M.gguf\", n_ctx=8192)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '''- Ng·ªØ c·∫£nh 1: Th√°i B√¨nh h∆∞·ªõng ƒë·∫øn l√† trung t√¢m c√¥ng nghi·ªáp, nƒÉng l∆∞·ª£ng c·ªßa v√πng V·ªõi ti·ªÅm nƒÉng s·∫µn c√≥, quy ho·∫°ch t·ªânh Th√°i B√¨nh th·ªùi k·ª≥ 2021-2030, t·∫ßm nh√¨n ƒë·∫øn nƒÉm 2050 x√°c ƒë·ªãnh t·ªânh s·∫Ω ph√°t tri·ªÉn c√¥ng nghi·ªáp theo h∆∞·ªõng hi·ªán ƒë·∫°i, b·ªÅn v·ªØng d·ª±a tr√™n nghi√™n c·ª©u ph√°t tri·ªÉn ƒëi·ªán gi√≥, ƒëi·ªán kh√≠, c√¢n b·∫±ng l∆∞·ª£ng ph√°t th·∫£i. S√°ng 5/3, UBND t·ªânh Th√°i B√¨nh t·ªï ch·ª©c H·ªôi ngh·ªã c√¥ng b·ªë quy ho·∫°ch c·ªßa t·ªânh th·ªùi k·ª≥ 2021-2030, t·∫ßm nh√¨n ƒë·∫øn nƒÉm 2050 v√† x√∫c ti·∫øn ƒë·∫ßu t∆∞ t·ªânh Th√°i B√¨nh. Ph√°t bi·ªÉu t·∫°i h·ªôi ngh·ªã, Ph√≥ Ch·ªß t·ªãch Th∆∞·ªùng tr·ª±c UBND t·ªânh Nguy·ªÖn Quang H∆∞ng cho bi·∫øt: M·ª•c ti√™u c·ªßa quy ho·∫°ch l√† ƒë·∫øn nƒÉm 2030, Th√°i B√¨nh tr·ªü th√†nh ƒë·ªãa ph∆∞∆°ng thu·ªôc nh√≥m ph√°t tri·ªÉn kh√° v√† l√† m·ªôt trong nh·ªØng trung t√¢m ph√°t tri·ªÉn c√¥ng nghi·ªáp c·ªßa v√πng ƒê·ªìng b·∫±ng s√¥ng H·ªìng, c√≥ c∆° c·∫•u kinh t·∫ø hi·ªán ƒë·∫°i v·ªõi c√¥ng nghi·ªáp l√† ƒë·ªông l·ª±c ch·ªß y·∫øu cho tƒÉng tr∆∞·ªüng ƒë·ªÉ Th√°i B√¨nh ph√°t tri·ªÉn nhanh, to√†n di·ªán v√† b·ªÅn v·ªØng. ƒê·∫øn nƒÉm 2050, Th√°i B√¨nh l√† t·ªânh ph√°t tri·ªÉn c·ªßa v√πng ƒê·ªìng b·∫±ng s√¥ng H·ªìng, tƒÉng tr∆∞·ªüng kinh t·∫ø d·ª±a tr√™n n·ªÅn t·∫£ng khoa h·ªçc c√¥ng ngh·ªá, ƒë·ªïi m·ªõi s√°ng t·∫°o v√† c√°c ng√†nh kinh t·∫ø tr·ª• c·ªôt c√≥ s·ª©c c·∫°nh tranh cao. Quy ho·∫°ch t·ªânh ƒë√£ x√°c ƒë·ªãnh 4 tr·ª• c·ªôt tƒÉng tr∆∞·ªüng, 3 kh√¢u ƒë·ªôt ph√°, 4 kh√¥ng gian kinh t·∫ø - x√£ h·ªôi, 3 h√†nh lang kinh t·∫ø, ƒë·ªãnh h∆∞·ªõng ph√°t tri·ªÉn c√°c ng√†nh v√† lƒ©nh v·ª±c v√† 6 nhi·ªám v·ª• tr·ªçng t√¢m. Quy ho·∫°ch t·ªânh c≈©ng c√≥ nhi·ªÅu ƒëi·ªÉm m·ªõi, ƒë·ªôt ph√° nh∆∞ m·ªü ra kh√¥ng gian ph√°t tri·ªÉn m·ªõi th√¥ng qua ho·∫°t ƒë·ªông ‚Äúl·∫•n bi·ªÉn‚Äù, t·∫°o qu·ªπ ƒë·∫•t cho c√°c ho·∫°t ƒë·ªông ch·ª©c nƒÉng, h√¨nh th√†nh kh√¥ng gian c√¥ng nghi·ªáp - ƒë√¥ th·ªã - d·ªãch v·ª•. V·ªÅ h·∫° t·∫ßng giao th√¥ng, Th√°i B√¨nh s·∫Ω ƒë·∫ßu t∆∞ 3 tuy·∫øn cao t·ªëc l√† cao t·ªëc Ninh B√¨nh - H·∫£i Ph√≤ng (CT.08), ƒë∆∞·ªùng v√†nh ƒëai 5 - H√† N·ªôi (CT.39) v√† tuy·∫øn CT.16 k·∫øt n·ªëi Khu kinh t·∫ø v·ªõi th√†nh ph·ªë Th√°i B√¨nh v√† v√πng kinh t·∫ø ph√≠a T√¢y B·∫Øc Th·ªß ƒë√¥. T·ªânh c≈©ng s·∫Ω ƒë·∫ßu t∆∞ 101km ƒë∆∞·ªùng s·∫Øt, kh·ªï ƒë∆∞·ªùng d·ª± ki·∫øn r·ªông 1.435 mm v√† s√¢n bay chuy√™n d·ª•ng n·∫±m ·ªü ven bi·ªÉn Th√°i B√¨nh. V·ªÅ ph√°t tri·ªÉn kinh t·∫ø, quy ho·∫°ch t·ªânh Th√°i B√¨nh x√°c ƒë·ªãnh t·ªânh s·∫Ω ph√°t tri·ªÉn c√¥ng nghi·ªáp theo h∆∞·ªõng hi·ªán ƒë·∫°i, c√¥ng ngh·ªá ti√™n ti·∫øn, gi√° tr·ªã gia tƒÉng cao, tham gia s√¢u, to√†n di·ªán v√†o m·∫°ng l∆∞·ªõi s·∫£n xu·∫•t, chu·ªói gi√° tr·ªã to√†n c·∫ßu, ph√°t huy c√°c ti·ªÅm nƒÉng, th·∫ø m·∫°nh ƒë·ªÉ ƒë∆∞a Th√°i B√¨nh tr·ªü th√†nh m·ªôt trong nh·ªØng trung t√¢m ph√°t tri·ªÉn c√¥ng nghi·ªáp, nƒÉng l∆∞·ª£ng c·ªßa v√πng ƒê·ªìng b·∫±ng s√¥ng H·ªìng. T·ªânh khuy·∫øn kh√≠ch ƒë·∫ßu t∆∞ ph√°t tri·ªÉn c√°c ng√†nh c√≥ th·∫ø m·∫°nh v√† c√≥ th·ªÉ t·∫°o ƒë·ªôt ph√° nh∆∞ nƒÉng l∆∞·ª£ng, c∆° kh√≠ ch·∫ø bi·∫øn, ch·∫ø t·∫°o, c√¥ng nghi·ªáp c√¥ng ngh·ªá cao, ƒëi·ªán - ƒëi·ªán t·ª≠, ch·∫ø bi·∫øn s·∫£n ph·∫©m n√¥ng, l√¢m nghi·ªáp v√† th·ªßy s·∫£n‚Ä¶ ƒê·ªìng th·ªùi, t·∫≠p trung nghi√™n c·ª©u ph√°t tri·ªÉn ƒëi·ªán gi√≥, ƒëi·ªán kh√≠ ƒë·ªÉ t·∫°o ngu·ªìn ƒëi·ªán s·∫°ch v√† c√¢n b·∫±ng l∆∞·ª£ng ph√°t th·∫£i, nghi√™n c·ª©u ƒë·∫ßu t∆∞ x√¢y d·ª±ng nh√† m√°y ch·∫ø bi·∫øn Condensate, chu·∫©n b·ªã m·ªçi ƒëi·ªÅu ki·ªán ƒë·ªÉ x√¢y d·ª±ng v√† ƒë∆∞a v√†o v·∫≠n h√†nh Nh√† m√°y nhi·ªát ƒëi·ªán LNG Th√°i B√¨nh. V·ªÅ n√¥ng nghi·ªáp, t·ªânh Th√°i B√¨nh v·∫´n x√°c ƒë·ªãnh ƒë√¢y l√† \\\"tr·ª• c·ªôt quan tr·ªçng\\\" trong ph√°t tri·ªÉn kinh t·∫ø c·ªßa t·ªânh, g√≥p ph·∫ßn b·∫£o ƒë·∫£m an ninh l∆∞∆°ng th·ª±c qu·ªëc gia, h∆∞·ªõng t·ªõi tr·ªü th√†nh trung t√¢m s·∫£n xu·∫•t n√¥ng nghi·ªáp h√†ng ƒë·∫ßu c·ªßa ƒê·ªìng b·∫±ng s√¥ng H·ªìng. Ph√°t bi·ªÉu t·∫°i h·ªôi ngh·ªã, Ph√≥ Th·ªß t∆∞·ªõng Ch√≠nh ph·ªß Tr·∫ßn L∆∞u Quang ƒë√°nh gi√° Th√°i B√¨nh c√≥ 4 ti·ªÅm nƒÉng, l·ª£i th·∫ø l·ªõn ƒë·ªÉ c√≥ th·ªÉ c√≥ s·ª± b·ª©t ph√° trong th·ªùi gian t·ªõi nh∆∞ v·ªã tr√≠ ƒë·ªãa l√Ω v√† ti·∫øp c·∫≠n ƒë·∫•t ƒëai thu·∫≠n l·ª£i; t·ª´ng l√† ƒë·ªãa ph∆∞∆°ng ƒëi ƒë·∫ßu trong x√¢y d·ª±ng n√¥ng th√¥n m·ªõi b√†i b·∫£n v√† nghi√™m t√∫c, nh·∫≠n ƒë∆∞·ª£c s·ª± quan t√¢m c·ªßa nhi·ªÅu th·∫ø h·ªá l√£nh ƒë·∫°o ƒê·∫£ng, Nh√† n∆∞·ªõc v√† c√≥ nhi·ªÅu doanh nh√¢n ng∆∞·ªùi Th√°i B√¨nh v√† lu√¥n h∆∞·ªõng v·ªÅ qu√™ h∆∞∆°ng; c√≥ s·ª± ƒëo√†n k·∫øt, th·ªëng nh·∫•t, tr∆∞·ªõc h·∫øt l√† trong t·∫≠p th·ªÉ l√£nh ƒë·∫°o. V·ªÅ v·ªã tr√≠ ƒë·ªãa l√Ω v√† ti·∫øp c·∫≠n ƒë·∫•t ƒëai, Ph√≥ Th·ªß t∆∞·ªõng cho r·∫±ng trong t∆∞∆°ng lai, khi Lu·∫≠t ƒê·∫•t ƒëai c√≥ hi·ªáu l·ª±c, Th√°i B√¨nh s·∫Ω c√≥ nhi·ªÅu ƒëi·ªÅu ki·ªán l·∫•n bi·ªÉn ƒë·ªÉ tri·ªÉn khai c√°c d·ª± √°n khu ƒë√¥ th·ªã, khu c√¥ng nghi·ªáp th√¢n thi·ªán v·ªõi m√¥i tr∆∞·ªùng. ƒê·ªëi v·ªõi n√¥ng nghi·ªáp, Ph√≥ Th·ªß t∆∞·ªõng nh·∫•n m·∫°nh v·ªÅ l√¢u d√†i Th√°i B√¨nh c√≥ th·ªÉ ghi ƒëi·ªÉm t·ª´ ph√°t tri·ªÉn c√¥ng nghi·ªáp nh∆∞ng tr∆∞·ªõc m·∫Øt, ƒë·∫∑c bi·ªát trong l√∫c kh√≥ khƒÉn th√¨ n√¥ng nghi·ªáp v·∫´n l√† n·ªÅn t·∫£ng r·∫•t qu√Ω gi√°. M·∫∑t kh√°c, ·ª©ng d·ª•ng c·ªßa c√¥ng ngh·ªá cao trong s·∫£n xu·∫•t n√¥ng nghi·ªáp s·∫Ω r√∫t ng·∫Øn th·ªùi gian l√†m ƒë·ªìng c·ªßa ng∆∞·ªùi n√¥ng d√¢n, t·∫°o ƒëi·ªÅu ki·ªán ƒë·ªÉ Th√°i B√¨nh huy ƒë·ªông ngu·ªìn nh√¢n l·ª±c trong n√¥ng nghi·ªáp sang ph√°t tri·ªÉn c√°c ng√†nh c√¥ng nghi·ªáp v√† d·ªãch v·ª•, m·ªôt l·ª£i th·∫ø m√† kh√¥ng ph·∫£i ƒë·ªãa ph∆∞∆°ng n√†o c≈©ng c√≥ ƒë∆∞·ª£c nh∆∞ Th√°i B√¨nh. B√™n c·∫°nh nh·ªØng l·ª£i th·∫ø tr√™n, l√£nh ƒë·∫°o Ch√≠nh ph·ªß ch·ªâ ra m·ªôt s·ªë kh√≥ khƒÉn m√† t·ªânh ph·∫£i ƒë·ªëi m·∫∑t nh∆∞ Th√°i B√¨nh ƒë√£ s·ª≠ d·ª•ng h·∫øt 1.600 ha ch·ªâ ti√™u ƒë·∫•t c√¥ng nghi·ªáp trong giai ƒëo·∫°n n√†y, ƒë√≤i h·ªèi ph·∫£i c√≥ ph∆∞∆°ng √°n gi·∫£i quy·∫øt th·∫•u ƒë√°o trong th·ªùi gian t·ªõi ƒë·ªÉ t·ªânh ti·∫øp t·ª•c ph√°t tri·ªÉn c√¥ng nghi·ªáp. ƒê·ªìng th·ªùi, Th√°i B√¨nh c≈©ng ph·∫£i c·∫°nh tranh v·ªõi nh·ªØng ƒë·ªãa ph∆∞∆°ng nh∆∞ H·∫£i Ph√≤ng, Qu·∫£ng Ninh trong thu h√∫t FDI trong khi ph√°t tri·ªÉn c∆° s·ªü h·∫° t·∫ßng ch∆∞a theo k·ªãp mong mu·ªën. Do v·∫≠y, khi tri·ªÉn khai quy ho·∫°ch t·ªânh, Ph√≥ Th·ªß t∆∞·ªõng nh·∫Øn nh·ªß t·ªõi ƒë·ªãa ph∆∞∆°ng 8 ch·ªØ: Tu√¢n th·ªß, linh ho·∫°t, ƒë·ªìng b·ªô v√† th·∫•u hi·ªÉu. ƒê·ªìng th·ªùi, t·ªânh c≈©ng ph·∫£i \\\"linh ho·∫°t\\\" trong t·ªï ch·ª©c th·ª±c hi·ªán, trong tr∆∞·ªùng h·ª£p c√° bi·ªát c·ª• th·ªÉ, ƒëi·ªÅu ch·ªânh m·ª•c ti√™u cho ph√π h·ª£p. S√°ng c√πng ng√†y, Ph√≥ Th·ªß t∆∞·ªõng Tr·∫ßn L∆∞u Quang ƒë√£ d·ª± L·ªÖ kh·ªüi c√¥ng d·ª± √°n Nh√† m√°y Pegavision Vi·ªát Nam t·∫°i khu c√¥ng nghi·ªáp Li√™n H√† Th√°i, huy·ªán Th√°i Th·ª•y, t·ªânh Th√°i B√¨nh \n",
    "\n",
    "- Ng·ªØ c·∫£nh 2: B√¨nh ƒê·ªãnh ƒë∆∞·ª£c ƒë·ªãnh h∆∞·ªõng l√† trung t√¢m khoa h·ªçc, c√¥ng ngh·ªá ƒë·ªïi m·ªõi s√°ng t·∫°o T·ªânh B√¨nh ƒê·ªãnh ƒë∆∞·ª£c ƒë·ªãnh h∆∞·ªõng ph√°t tri·ªÉn ng√†nh c√¥ng nghi·ªáp ph√°t tri·ªÉn theo h∆∞·ªõng hi·ªán ƒë·∫°i, quy m√¥ l·ªõn, tr·ªü th√†nh m·ªôt trong nh·ªØng trung t√¢m c√¥ng nghi·ªáp ch·∫ø bi·∫øn ch·∫ø t·∫°o v√† c√¥ng ngh·ªá cao c·ªßa v√πng B·∫Øc Trung B·ªô v√† duy√™n h·∫£i Trung B·ªô. Theo Quy ho·∫°ch t·ªânh B√¨nh ƒê·ªãnh th·ªùi k·ª≥ 2021 - 2030, t·∫ßm nh√¨n ƒë·∫øn nƒÉm 2050 v·ª´a ƒë∆∞·ª£c Th·ªß t∆∞·ªõng Ch√≠nh ph·ªß ph√™ duy·ªát, t·ªânh B√¨nh ƒê·ªãnh ƒë∆∞·ª£c ƒë·ªãnh h∆∞·ªõng ph√°t tri·ªÉn ng√†nh c√¥ng nghi·ªáp ph√°t tri·ªÉn theo h∆∞·ªõng hi·ªán ƒë·∫°i, quy m√¥ l·ªõn, tr·ªü th√†nh m·ªôt trong nh·ªØng trung t√¢m c√¥ng nghi·ªáp ch·∫ø bi·∫øn ch·∫ø t·∫°o v√† c√¥ng ngh·ªá cao c·ªßa v√πng B·∫Øc Trung B·ªô v√† duy√™n h·∫£i Trung B·ªô. Ng√†nh c√¥ng nghi·ªáp tƒÉng tr∆∞·ªüng nhanh, b·ªÅn v·ªØng, h∆∞·ªõng t·ªõi tƒÉng tr∆∞·ªüng xanh, kinh t·∫ø tu·∫ßn ho√†n l√† tr·ª• c·ªôt ƒë·ªÉ ph√°t tri·ªÉn v√† chuy·ªÉn d·ªãch c∆° c·∫•u kinh t·∫ø c·ªßa t·ªânh. Ng√†nh ch·∫ø bi·∫øn, ch·∫ø t·∫°o c√¥ng ngh·ªá cao (d·ªãch chuy·ªÉn ng√†nh c√¥ng nghi·ªáp ch·∫ø bi·∫øn, ch·∫ø t·∫°o sang lƒ©nh v·ª±c s·∫£n xu·∫•t c√≥ gi√° tr·ªã gia tƒÉng cao nh∆∞: ch·∫ø bi·∫øn s√¢u n√¥ng - th·ªßy - h·∫£i s·∫£n, linh ki·ªán ƒëi·ªán t·ª≠, b√°n d·∫´n, d∆∞·ª£c ph·∫©m), c√¥ng ngh·ªá th√¥ng tin, tr√≠ tu·ªá nh√¢n t·∫°o tr·ªü th√†nh m·ªôt trong nh·ªØng lƒ©nh v·ª±c ƒë·ªôt ph√°, g√≥p ph·∫ßn ƒë∆∞a t·ªânh B√¨nh ƒê·ªãnh tr·ªü th√†nh m·ªôt trung t√¢m khoa h·ªçc, c√¥ng ngh·ªá ƒë·ªïi m·ªõi s√°ng t·∫°o c·ªßa v√πng v√† c·∫£ n∆∞·ªõc. Quy ho·∫°ch t·ªânh B√¨nh ƒê·ªãnh th·ªùi k·ª≥ 2021 - 2030, t·∫ßm nh√¨n ƒë·∫øn nƒÉm 2050 ƒë·∫∑t ra y√™u c·∫ßu t·ªânh n√†y ph·∫£i ch√∫ tr·ªçng thu h√∫t ƒë·∫ßu t∆∞ ph√°t tri·ªÉn nƒÉng l∆∞·ª£ng t√°i t·∫°o, nƒÉng l∆∞·ª£ng s·∫°ch nh∆∞ ƒëi·ªán gi√≥ ven b·ªù, ƒëi·ªán gi√≥ ngo√†i kh∆°i, ƒëi·ªán m·∫∑t tr·ªùi, ƒëi·ªán sinh kh·ªëi v√† ngu·ªìn nƒÉng l∆∞·ª£ng m·ªõi (hydrogen/amoniac xanh‚Ä¶); c√°c d·ª± √°n s·∫£n xu·∫•t th√©p quy m√¥ l·ªõn, ƒë√≥ng t√†u, s·∫£n xu·∫•t thi·∫øt b·ªã ph·ª• tr·ª£ ƒëi·ªán gi√≥ c√≥ c√¥ng ngh·ªá ti√™n ti·∫øn ƒë·ªÉ n√¢ng c·∫•p x√¢y d·ª±ng h·∫° t·∫ßng k·ªπ thu·∫≠t s·∫£n xu·∫•t, th√∫c ƒë·∫©y chuy·ªÉn d·ªãch kinh t·∫ø. Quy ho·∫°ch t·ªânh B√¨nh ƒê·ªãnh th·ªùi k·ª≥ 2021 - 2030, t·∫ßm nh√¨n ƒë·∫øn nƒÉm 2050 c≈©ng ƒë·∫∑t ra m·ª•c ti√™u ƒë·∫øn nƒÉm 2030, B√¨nh ƒê·ªãnh tr·ªü th√†nh t·ªânh ph√°t tri·ªÉn thu·ªôc nh√≥m d·∫´n ƒë·∫ßu v√πng B·∫Øc Trung B·ªô v√† duy√™n h·∫£i Trung B·ªô, l√† trung t√¢m c√¥ng nghi·ªáp ch·∫ø bi·∫øn, ch·∫ø t·∫°o, d·ªãch v·ª•, du l·ªãch v√† vƒÉn h√≥a ph√≠a Nam c·ªßa v√πng; trung t√¢m l·ªõn c·ªßa c·∫£ n∆∞·ªõc v·ªÅ ph√°t tri·ªÉn kinh t·∫ø bi·ªÉn; tr·ªçng ƒëi·ªÉm du l·ªãch qu·ªëc gia v√† qu·ªëc t·∫ø v·ªõi h·ªá th·ªëng k·∫øt c·∫•u h·∫° t·∫ßng kinh t·∫ø ƒë·ªìng b·ªô, hi·ªán ƒë·∫°i; kinh t·∫ø c·ªßa t·ªânh ph√°t tri·ªÉn nhanh, b·ªÅn v·ªØng v√† xanh d·ª±a tr√™n c√°c tr·ª• c·ªôt tƒÉng tr∆∞·ªüng c√¥ng nghi·ªáp, d·ªãch v·ª• du l·ªãch, c·∫£ng bi·ªÉn - logistics; n√¥ng nghi·ªáp ·ª©ng d·ª•ng c√¥ng ngh·ªá cao; ƒë√¥ th·ªã h√≥a; th·ª±c hi·ªán th√†nh c√¥ng c√°c m·ª•c ti√™u chuy·ªÉn ƒë·ªïi s·ªë, ƒë·ªïi m·ªõi s√°ng t·∫°o, c·∫£i thi·ªán m·∫°nh m·∫Ω m√¥i tr∆∞·ªùng ƒë·∫ßu t∆∞ kinh doanh, tr·ªü th√†nh ƒëi·ªÉm ƒë·∫øn ƒë·∫ßu t∆∞ h·∫•p d·∫´n c·ªßa c√°c doanh nghi·ªáp l·ªõn trong v√† ngo√†i n∆∞·ªõc; ch·ªâ s·ªë nƒÉng l·ª±c c·∫°nh tranh c·∫•p t·ªânh thu·ªôc nh√≥m cao c·ªßa c·∫£ n∆∞·ªõc; k·∫øt c·∫•u h·∫° t·∫ßng kinh t·∫ø - x√£ h·ªôi ƒë·ªìng b·ªô, hi·ªán ƒë·∫°i, h·ªá th·ªëng ƒë√¥ th·ªã ph√°t tri·ªÉn theo h∆∞·ªõng ƒë√¥ th·ªã th√¥ng minh, k·∫øt n·ªëi thu·∫≠n ti·ªán v·ªõi c√°c trung t√¢m kinh t·∫ø c·ªßa v√πng, c·∫£ n∆∞·ªõc v√† qu·ªëc t·∫ø. \n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "- Ng·ªØ c·∫£nh 3: . Ch·ªß t·ªãch UBND t·ªânh Qu·∫£ng Ninh cho bi·∫øt, t·ªânh ƒë·∫∑t m·ª•c ti√™u h∆∞·ªõng ƒë·∫øn nƒÉm 2030 tr·ªü th√†nh m·ªôt t·ªânh ti√™u bi·ªÉu c·ªßa c·∫£ n∆∞·ªõc v·ªÅ m·ªçi m·∫∑t; t·ªânh ki·ªÉu m·∫´u gi√†u ƒë·∫πp, vƒÉn minh, hi·ªán ƒë·∫°i, n√¢ng cao ƒë·ªùi s·ªëng m·ªçi m·∫∑t c·ªßa nh√¢n d√¢n; c·ª±c tƒÉng tr∆∞·ªüng c·ªßa khu v·ª±c ph√≠a B·∫Øc, m·ªôt trong nh·ªØng trung t√¢m ph√°t tri·ªÉn nƒÉng ƒë·ªông, to√†n di·ªán; trung t√¢m du l·ªãch qu·ªëc t·∫ø, trung t√¢m kinh t·∫ø bi·ªÉn, c·ª≠a ng√µ c·ªßa V√πng kinh t·∫ø tr·ªçng ƒëi·ªÉm B·∫Øc B·ªô v√† c·∫£ n∆∞·ªõc. ƒê·ªÉ ƒë·∫°t ƒë∆∞·ª£c nh·ªØng m·ª•c ti√™u tr√™n, t·ªânh Qu·∫£ng Ninh x√°c ƒë·ªãnh s·ª± ƒë√≥ng g√≥p, quan t√¢m c·ªßa c·ªông ƒë·ªìng doanh nghi·ªáp, nh·∫•t l√† c√°c doanh nghi·ªáp h√†ng ƒë·∫ßu Vi·ªát Nam ‚Äúc√°c s·∫øu ƒë·∫ßu ƒë√†n‚Äù l√† m·ªôt trong nh·ªØng y·∫øu t·ªë then ch·ªët quy·∫øt ƒë·ªãnh. Do v·∫≠y, t·ªânh Qu·∫£ng Ninh r·∫•t mong nh·∫≠n ƒë∆∞·ª£c s·ª± quan t√¢m, nghi√™n c·ª©u ƒë·∫ßu t∆∞ h·ª£p t√°c c·ªßa c√°c Doanh nghi·ªáp h√†ng ƒë·∫ßu Vi·ªát Nam trong th·ªùi gian t·ªõi, nh·∫•t l√† trong vi·ªác ƒë·∫ßu t∆∞ c√°c d·ª± √°n c√≥ h√†m l∆∞·ª£ng c√¥ng ngh·ªá cao, c√¥ng ngh·ªá ti√™n ti·∫øn, qu·∫£n tr·ªã hi·ªán ƒë·∫°i, gi√° tr·ªã gia tƒÉng cao, c√≥ t√°c ƒë·ªông lan t·ªèa. T·ªânh Qu·∫£ng Ninh cam k·∫øt t·∫°o ƒëi·ªÅu ki·ªán thu·∫≠n l·ª£i nh·∫•t cho doanh nghi·ªáp ph√°t tri·ªÉn h∆°n n·ªØa khi ƒë·∫ßu t∆∞ kinh doanh tr√™n ƒë·ªãa b√†n t·ªânh; cam k·∫øt ƒë·ªìng h√†nh, l·∫Øng nghe ti·∫øng n√≥i c·ªßa c·ªông ƒë·ªìng doanh nghi·ªáp, c√°c nh√† ƒë·∫ßu t∆∞; c√πng trƒÉn tr·ªü, tr√°ch nhi·ªám, gi·∫£i quy·∫øt th·∫•u ƒë√°o, v√†o cu·ªôc th·ª±c ch·∫•t, hi·ªáu qu·∫£ ƒë·ªëi v·ªõi t·ª´ng kh√≥ khƒÉn, v∆∞·ªõng m·∫Øc v·ªõi m·ª•c ti√™u tƒÉng c∆∞·ªùng ni·ªÅm tin v√† n√¢ng cao s·ª± h√†i l√≤ng c·ªßa c√° nh√¢n, t·ªï ch·ª©c, doanh nghi·ªáp l√† th∆∞·ªõc ƒëo ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng ph·ª•c v·ª•, ch·∫•t l∆∞·ª£ng ƒëi·ªÅu h√†nh c·ªßa c∆° quan h√†nh ch√≠nh nh√† n∆∞·ªõc t·ª´ c·∫•p t·ªânh ƒë·∫øn c√°c c·∫•p c∆° s·ªü. T·ªânh Qu·∫£ng Ninh s·∫Ω tri·ªÉn khai m·ªôt c√°ch hi·ªáu qu·∫£ nh·∫•t Quy ho·∫°ch t·ªânh, quy ho·∫°ch c√°c ƒë·ªãa ph∆∞∆°ng; chu·∫©n b·ªã m·∫∑t b·∫±ng s·∫°ch; qu·ªπ ƒë·∫•t t√°i ƒë·ªãnh c∆∞; ƒë·∫£m b·∫£o ngu·ªìn cung ƒëi·ªán, n∆∞·ªõc v√† vi·ªÖn th√¥ng theo y√™u c·∫ßu; x√¢y d·ª±ng c√°c ch√≠nh s√°ch ƒë·ªôt ph√° ƒë·ªÉ thu h√∫t ngu·ªìn nh√¢n l·ª±c ch·∫•t l∆∞·ª£ng cao th√¥ng qua vi·ªác c·∫£i thi·ªán nh√† ·ªü v√† c∆° s·ªü vƒÉn h√≥a ƒë·ªÉ ƒë·∫£m b·∫£o ƒë·ªùi s·ªëng v·∫≠t ch·∫•t v√† tinh th·∫ßn cho ng∆∞·ªùi lao ƒë·ªông. ƒê·ªìng th·ªùi b·∫£o v·ªá quy·ªÅn v√† l·ª£i √≠ch ch√≠nh ƒë√°ng, h·ª£p ph√°p c·ªßa nh√† ƒë·∫ßu t∆∞, doanh nghi·ªáp v√†o t·ªânh; b·∫£o ƒë·∫£m h√†i h√≤a l·ª£i √≠ch gi·ªØa nh√† n∆∞·ªõc, nh√† ƒë·∫ßu t∆∞, ng∆∞·ªùi lao ƒë·ªông v√† ng∆∞·ªùi d√¢n.'''\n",
    "\n",
    "question = '''Theo quy ho·∫°ch t·ªânh T√¢y Ninh th·ªùi k·ª≥ 2021 - 2030, t·∫ßm nh√¨n ƒë·∫øn nƒÉm 2050, t·ªânh s·∫Ω t·∫≠p trung ph√°t tri·ªÉn c√¥ng nghi·ªáp v√† d·ªãch v·ª• du l·ªãch. Trong b·ªëi c·∫£nh c·∫°nh tranh v·ªõi c√°c t·ªânh l√¢n c·∫≠n, y·∫øu t·ªë n√†o ƒë∆∞·ª£c coi l√† quan tr·ªçng nh·∫•t ƒë·ªÉ T√¢y Ninh c√≥ th·ªÉ thu h√∫t ƒë·∫ßu t∆∞ v√† ph√°t tri·ªÉn nhanh, to√†n di·ªán v√† b·ªÅn v·ªØng?'''\n",
    "\n",
    "\n",
    "'''Tr·∫£ l·ªùi:\n",
    "Trong ng·ªØ c·∫£nh ƒë∆∞·ª£c cung c·∫•p, kh√¥ng c√≥ th√¥ng tin v·ªÅ quy ho·∫°ch t·ªânh T√¢y Ninh th·ªùi k·ª≥ 2021 - 2030, t·∫ßm nh√¨n ƒë·∫øn nƒÉm 2050. Do ƒë√≥, kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi ch√≠nh x√°c d·ª±a tr√™n c√°c th√¥ng tin ƒë√£ cung c·∫•p. N·∫øu b·∫°n c√≥ th√™m th√¥ng tin v·ªÅ quy ho·∫°ch t·ªânh T√¢y Ninh, vui l√≤ng cung c·∫•p ƒë·ªÉ t√¥i c√≥ th·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ch√≠nh x√°c v√† ƒë·∫ßy ƒë·ªß.\n",
    "'''\n",
    "\n",
    "\n",
    "system_prompt = \"B·∫°n l√† m·ªôt tr·ª£ l√≠ Ti·∫øng Vi·ªát nhi·ªát t√¨nh v√† trung th·ª±c. H√£y lu√¥n tr·∫£ l·ªùi m·ªôt c√°ch h·ªØu √≠ch nh·∫•t c√≥ th·ªÉ.\"\n",
    "template = f\"\"\"Ch√∫ √Ω c√°c y√™u c·∫ßu sau:\n",
    "- C√¢u tr·∫£ l·ªùi ph·∫£i ch√≠nh x√°c v√† ƒë·∫ßy ƒë·ªß n·∫øu ng·ªØ c·∫£nh c√≥ c√¢u tr·∫£ l·ªùi. \n",
    "- Ch·ªâ s·ª≠ d·ª•ng c√°c th√¥ng tin c√≥ trong ng·ªØ c·∫£nh ƒë∆∞·ª£c cung c·∫•p.\n",
    "- Ch·ªâ c·∫ßn t·ª´ ch·ªëi tr·∫£ l·ªùi v√† kh√¥ng suy lu·∫≠n g√¨ th√™m n·∫øu ng·ªØ c·∫£nh kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi.\n",
    "\n",
    "H√£y tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n ng·ªØ c·∫£nh:\n",
    "\n",
    "### Ng·ªØ c·∫£nh :\n",
    "{context}\n",
    "\n",
    "### C√¢u h·ªèi :\n",
    "{question}\n",
    "\n",
    "### Tr·∫£ l·ªùi :\n",
    "\"\"\"\n",
    "\n",
    "full_prompt = f\"[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n{template} [/INST]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 131 prefix-match hit, remaining 2758 prompt tokens to eval\n"
     ]
    }
   ],
   "source": [
    "buffer = ''\n",
    "answer = \"\"\n",
    "for chunk in llm(full_prompt, max_tokens=1024, stream=True):\n",
    "    text = chunk[\"choices\"][0][\"text\"]\n",
    "    buffer+=text\n",
    "    # if 'Llama.generate: 4392 prefix-match hit, remaining 1 prompt tokens to eval' in buffer:\n",
    "    #     continue\n",
    "    if '[/INST]' in buffer:\n",
    "        break\n",
    "    answer+=text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Kh√¥ng c√≥ th√¥ng tin v·ªÅ quy ho·∫°ch t·ªânh T√¢y Ninh th·ªùi k·ª≥ 2021 - 2030, t·∫ßm nh√¨n ƒë·∫øn nƒÉm 2050 trong ng·ªØ c·∫£nh ƒë∆∞·ª£c cung c·∫•p. Do ƒë√≥, kh√¥ng th·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c c√¢u h·ªèi n√†y d·ª±a tr√™n c√°c th√¥ng tin ƒë√£ cho. N·∫øu b·∫°n c√≥ th√™m th√¥ng tin v·ªÅ T√¢y Ninh, t√¥i s·∫Ω r·∫•t vui ƒë∆∞·ª£c gi√∫p ƒë·ª°. \n"
     ]
    }
   ],
   "source": [
    "print(answer.split('[/INST')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[32m      3\u001b[39m path = \u001b[33m'\u001b[39m\u001b[33mAITeamVN/Vi-Qwen2-1.5B-RAG\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "path = 'AITeamVN/Vi-Qwen2-1.5B-RAG'\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    path,\n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\",\n",
    "    use_cache=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "\n",
    "system_prompt = \"B·∫°n l√† m·ªôt tr·ª£ l√≠ Ti·∫øng Vi·ªát nhi·ªát t√¨nh v√† trung th·ª±c. H√£y lu√¥n tr·∫£ l·ªùi m·ªôt c√°ch h·ªØu √≠ch nh·∫•t c√≥ th·ªÉ.\"\n",
    "template = '''Ch√∫ √Ω c√°c y√™u c·∫ßu sau:\n",
    "- C√¢u tr·∫£ l·ªùi ph·∫£i ch√≠nh x√°c v√† ƒë·∫ßy ƒë·ªß n·∫øu ng·ªØ c·∫£nh c√≥ c√¢u tr·∫£ l·ªùi. \n",
    "- Ch·ªâ s·ª≠ d·ª•ng c√°c th√¥ng tin c√≥ trong ng·ªØ c·∫£nh ƒë∆∞·ª£c cung c·∫•p.\n",
    "- Ch·ªâ c·∫ßn t·ª´ ch·ªëi tr·∫£ l·ªùi v√† kh√¥ng suy lu·∫≠n g√¨ th√™m n·∫øu ng·ªØ c·∫£nh kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi.\n",
    "H√£y tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n ng·ªØ c·∫£nh:\n",
    "### Ng·ªØ c·∫£nh :\n",
    "{context}\n",
    "\n",
    "### C√¢u h·ªèi :\n",
    "{question}\n",
    "\n",
    "### Tr·∫£ l·ªùi :'''\n",
    "\n",
    "# V√≠ d·ª•\n",
    "context = '''Thu·ªëc Insuact 10 tr·ªã b·ªánh g√¨? Thu·ªëc Insuact 10mg c√≥ th√†nh ph·∫ßn ch√≠nh l√† Atorvastatin. Thu·ªëc Insuact 10 c√≥ t√°c d·ª•ng l√†m gi·∫£m cholesterol v√† triglycerid trong m√°u ·ªü b·ªánh nh√¢n tƒÉng cholesterol m√°u nguy√™n ph√°t, r·ªëi lo·∫°n lipid m√°u h·ªón h·ª£p. 1. Thu·ªëc Insuact 10 tr·ªã b·ªánh g√¨? Thu·ªëc Insuact 10 thu·ªôc nh√≥m thu·ªëc ƒëi·ªÅu tr·ªã r·ªëi lo·∫°n lipid m√°u, c√≥ th√†nh ph·∫ßn ch√≠nh l√† Atorvastatin 10mg. Atorvastatin c√≥ t√°c d·ª•ng l√†m gi·∫£m cholesterol, ·ª©c ch·∫ø enzym t·∫°o cholesterol ·ªü gan. Atorvastatin l√†m gi·∫£m cholesterol chung bao g·ªìm cholesterol LDL , triglycerid trong m√°u. Thu·ªëc Insuact 10mg ƒë∆∞·ª£c b√†o ch·∫ø d∆∞·ªõi d·∫°ng vi√™n n√©n bao phim, ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh d√πng trong nh·ªØng tr∆∞·ªùng h·ª£p sau: √êi·ªÅu tr·ªã h·ªó tr·ª£ tƒÉng cholesterol m√°u nguy√™n ph√°t v√† r·ªëi lo·∫°n lipid m√°u h·ªón h·ª£p tr√™n b·ªánh nh√¢n ƒëang √°p d·ª•ng ch·∫ø ƒë·ªô ƒÉn ki√™ng ƒë·ªÉ l√†m gi·∫£m cholesterol to√†n ph·∫ßn , cholesterol LDL , apolipoprotein B, triglycerid v√† tƒÉng cholesterol HDL . Insuact 10 c≈©ng ƒë∆∞·ª£c d√πng ƒë·ªÉ ƒëi·ªÅu tr·ªã r·ªëi lo·∫°n betalipoprotein trong m√°u nguy√™n ph√°t. √êi·ªÅu tr·ªã h·ªó tr·ª£ tƒÉng cholesterol trong m√°u c√≥ t√≠nh gia ƒë√¨nh ƒë·ªìng h·ª£p t·ª≠ tr√™n b·ªánh nh√¢n ƒëang √°p d·ª•ng c√°c bi·ªán ph√°p l√†m gi·∫£m lipid kh√°c ƒë·ªÉ l√†m gi·∫£m cholesterol to√†n ph·∫ßn v√† cholesterol LDL. 2. Li·ªÅu d√πng v√† c√°ch d√πng thu·ªëc Insuact 10 C√°ch d√πng thu·ªëc Insuact 10: Thu·ªëc ƒë∆∞·ª£c d√πng theo ƒë∆∞·ªùng u·ªëng, u·ªëng khi b·ª•ng ƒë√≥i ho·∫∑c no ƒë·ªÅu ƒë∆∞·ª£c, c√≥ th·ªÉ u·ªëng v√†o b·∫•t c·ª© l√∫c n√†o trong ng√†y. Li·ªÅu d√πng thu·ªëc Insuact 10mg kh·ªüi ƒë·∫ßu l√† 10mg/l·∫ßn/ng√†y, t·ªëi ƒëa l√† 80mg/l·∫ßn/ng√†y. Li·ªÅu d√πng thu·ªëc Insuact 10 t√πy v√†o m·ª•c ƒë√≠ch ƒëi·ªÅu tr·ªã c·ª• th·ªÉ nh∆∞ sau: TƒÉng cholesterol m√°u nguy√™n ph√°t v√† r·ªëi lo·∫°n lipid m√°u ph·ªëi h·ª£p: 10mg/l·∫ßn/ng√†y, sau 2 - 4 tu·∫ßn s·∫Ω th·∫•y hi·ªáu qu·∫£ c·ªßa thu·ªëc. Thu·ªëc c·∫ßn ƒë∆∞·ª£c ƒë∆∞·ª£c s·ª≠ d·ª•ng duy tr√¨ trong th·ªùi gian d√†i ƒë·ªÉ c√≥ hi·ªáu qu·∫£. TƒÉng cholesterol trong m√°u c√≥ t√≠nh gia ƒë√¨nh ƒë·ªìng h·ª£p t·ª≠: Li·ªÅu th∆∞·ªùng d√πng l√† thu·ªëc Insuact 10mg /l·∫ßn/ng√†y v√† t·ªëi ƒëa l√† 80mg/l·∫ßn/ng√†y. R·ªëi lo·∫°n lipid m√°u nghi√™m tr·ªçng ·ªü tr·∫ª t·ª´ 10 - 17 tu·ªïi: 10mg/l·∫ßn/ng√†y, sau ƒë√≥ tƒÉng l√™n 20mg/l·∫ßn/ng√†y t√πy v√†o c∆° ƒë·ªãa, ti·∫øn tri·ªÉn b·ªánh v√† kh·∫£ nƒÉng dung n·∫°p thu·ªëc c·ªßa ng∆∞·ªùi b·ªánh. Th·ªùi gian ƒëi·ªÅu ch·ªânh li·ªÅu thu·ªëc t·ªëi thi·ªÉu l√† 4 tu·∫ßn. 3. T√°c d·ª•ng ph·ª• c·ªßa thu·ªëc Insuact 10mg Thu·ªëc Insuact 10 c√≥ th·ªÉ g√¢y m·ªôt s·ªë t√°c d·ª•ng ph·ª• kh√¥ng mong mu·ªën v·ªõi t·∫ßn su·∫•t nh∆∞ sau: Th∆∞·ªùng g·∫∑p: Vi√™m m≈©i - h·ªçng, ph·∫£n ·ª©ng d·ªã ·ª©ng, tƒÉng ƒë∆∞·ªùng huy·∫øt, nh·ª©c ƒë·∫ßu, ƒëau thanh qu·∫£n, ch·∫£y m√°u cam , ƒëau c∆°, co th·∫Øt c∆°, ƒëau kh·ªõp, s∆∞ng kh·ªõp, ƒëau c√°c chi, ƒëau l∆∞ng, x√©t nghi·ªám gan b·∫•t th∆∞·ªùng, tƒÉng creatine kinase trong m√°u, bu·ªìn n√¥n, kh√≥ ti√™u, ƒë·∫ßy h∆°i, t√°o b√≥n, ti√™u ch·∫£y. √çt g·∫∑p: Insuact 10 √≠t g√¢y h·∫° ƒë∆∞·ªùng huy·∫øt, tƒÉng c√¢n, ch√°n ƒÉn, m·∫•t ng·ªß, g·∫∑p √°c m·ªông, cho√°ng v√°ng, d·ªã c·∫£m, m·∫•t tr√≠ nh·ªõ, gi·∫£m c·∫£m gi√°c, lo·∫°n v·ªã gi√°c , n√¥n, ƒëau b·ª•ng, ·ª£ h∆°i, vi√™m t·ª•y, vi√™m gan, n·ªïi m√†y ƒëay , ph√°t ban, ng·ª©a, r·ª•ng t√≥c, ƒëau c·ªï, m·ªèi c∆°, m·ªát m·ªèi, suy nh∆∞·ª£c, ƒëau ng·ª±c, ph√π ngo·∫°i bi√™n, s·ªët, xu·∫•t hi·ªán b·∫°ch c·∫ßu trong n∆∞·ªõc ti·ªÉu, nh√¨n m·ªù, √π tai. Hi·∫øm g·∫∑p: Insuact 10 hi·∫øm khi l√†m gi·∫£m ti·ªÉu c·∫ßu, b·ªánh l√Ω th·∫ßn kinh ngo·∫°i bi√™n, hoa m·∫Øt, ·ª© m·∫≠t, ph√π th·∫ßn kinh, n·ªïi h·ªìng ban, h·ªôi ch·ª©ng ho·∫°i t·ª≠ da nhi·ªÖm ƒë·ªôc , h·ªôi ch·ª©ng Stevens-Johnson , b·ªánh c∆°, vi√™m c∆°, ti√™u c∆° v√¢n, b·ªánh g√¢n, ƒë√¥i khi nghi√™m tr·ªçng h∆°n c√≥ th·ªÉ ƒë·ª©t g√¢n. R·∫•t hi·∫øm g·∫∑p: Insuact 10 r·∫•t hi·∫øm khi g√¢y s·ªëc ph·∫£n v·ªá , m·∫•t th√≠nh gi√°c , suy gan , h·ªôi ch·ª©ng to v√∫ ·ªü nam gi·ªõi. Kh√¥ng r√µ t·∫ßn su·∫•t: Ho·∫°i t·ª≠ c∆° t·ª± mi·ªÖn trung gian. 4. M·ªôt s·ªë l∆∞u √Ω khi d√πng thu·ªëc Insuact 10mg Kh√¥ng d√πng thu·ªëc Insuact v·ªõi ng∆∞·ªùi b·ªã qu√° m·∫´n v·ªõi th√†nh ph·∫ßn c·ªßa thu·ªëc, ng∆∞·ªùi c√≥ b·ªánh gan ho·∫°t ƒë·ªông ho·∫∑c tƒÉng transaminase huy·∫øt thanh v√¥ cƒÉn k√©o d√†i, ph·ª• n·ªØ ƒëang mang thai ho·∫∑c nu√¥i con cho b√∫, ph·ª• n·ªØ ƒëang c√≥ √Ω ƒë·ªãnh mang thai. Thu·ªëc Insuact 10mg ch·ªâ ƒë∆∞·ª£c d√πng ·ªü b·ªánh nh√¢n c√≥ nguy c∆° x∆° v·ªØa m·∫°ch m√°u cao do tƒÉng cholesterol trong m√°u v√† ph·∫£i k·∫øt h·ª£p v·ªõi ch·∫ø ƒë·ªô ƒÉn ki√™ng √≠t ch·∫•t b√©o b√£o h√≤a , √≠t cholesterol v√† ng∆∞·ªùi b·ªánh ƒëang √°p d·ª•ng c√°c bi·ªán ph√°p ƒëi·ªÅu tr·ªã kh√¥ng d√πng thu·ªëc kh√°c. Tr∆∞·ªõc khi ƒëi·ªÅu tr·ªã v·ªõi Insuact 10 , ng∆∞·ªùi b·ªánh c·∫ßn ƒë∆∞·ª£c lo·∫°i tr·ª´ c√°c nguy√™n nh√¢n th·ª© ph√°t g√¢y tƒÉng cholesterol bao g·ªìm suy tuy·∫øn gi√°p , ti·ªÉu ƒë∆∞·ªùng kh√≥ ki·ªÉm so√°t, h·ªôi ch·ª©ng th·∫≠n h∆∞, nghi·ªán r∆∞·ª£u, b·ªánh gan t·∫Øc ngh·∫Ωn, r·ªëi lo·∫°n protein trong m√°u, .... Ngo√†i ra, ng∆∞·ªùi b·ªánh c≈©ng c·∫ßn ƒë∆∞·ª£c ki·ªÉm tra, ƒëo l∆∞·ªùng n·ªìng ƒë·ªô lipid m√°u. Tr∆∞·ªõc khi ƒëi·ªÅu tr·ªã v·ªõi thu·ªëc Insuact 10mg , c·∫ßn ki·ªÉm tra ch·ª©c nƒÉng gan v√† trong qu√° tr√¨nh d√πng thu·ªëc, ng∆∞·ªùi b·ªánh c·∫ßn theo d√µi, ki·ªÉm tra ch·ª©c nƒÉng gan th∆∞·ªùng xuy√™n. Ng∆∞·ªùi c√≥ ti·ªÅn s·ª≠ m·∫Øc b·ªánh gan do r∆∞·ª£u, b·ªã nghi·ªán r∆∞·ª£u c·∫ßn th·∫≠n tr·ªçng khi d√πng Insuact 10 . Tr∆∞·ªõc khi d√πng thu·ªëc, ng∆∞·ªùi b·ªánh c·∫ßn ƒë∆∞·ª£c c·∫£nh b√°o nguy c∆° g·∫∑p ph·∫£i c√°c v·∫•n ƒë·ªÅ v·ªÅ c∆° nh∆∞ cƒÉng c∆° , ƒëau c∆°, y·∫øu c∆°. Thu·ªëc Insuact 10mg c√≥ th·ªÉ t∆∞∆°ng t√°c v·ªõi c√°c thu·ªëc: TƒÉng nguy c∆° t·ªïn th∆∞∆°ng c∆° (ƒë·∫∑c bi·ªát c∆° v√¢n) khi d√πng ƒë·ªìng th·ªùi v·ªõi thu·ªëc ƒëi·ªÅu tr·ªã vi√™m gan C v√† HIV, h·∫° cholesterol m√°u nh√≥m fibrat kh√°c, thu·ªëc ·ª©c ch·∫ø mi·ªÖn d·ªãch; tƒÉng th·ªùi gian ch·∫£y m√°u ho·∫∑c th·ªùi gian prothrombin khi d√πng ph·ªëi h·ª£p v·ªõi thu·ªëc ch·ªëng ƒë√¥ng, indandione; tƒÉng nh·∫π n·ªìng ƒë·ªô digoxin trong huy·∫øt thanh khi d√πng ph·ªëi h·ª£p v·ªõi Digoxin'''\n",
    "question = '''Insuact 10mg ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh d√πng trong nh·ªØng tr∆∞·ªùng h·ª£p n√†o v√† li·ªÅu d√πng c·ª• th·ªÉ ra sao?'''\n",
    "conversation = [{\"role\": \"system\", \"content\": system_prompt }]\n",
    "conversation.append({\"role\": \"user\", \"content\": template.format(context = context, question = question)})\n",
    "text = tokenizer.apply_chat_template(\n",
    "    conversation,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True)\n",
    "model_inputs = tokenizer(text,return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    max_new_tokens=2048,\n",
    "    temperature = 0.1,\n",
    "    #top_p=0.95,\n",
    "    #top_k=40,\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(response)\n",
    "\n",
    "'''Tr·∫£ l·ªùi:\n",
    "D·ª±a tr√™n ng·ªØ c·∫£nh cung c·∫•p, Insuact 10mg ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh d√πng trong c√°c tr∆∞·ªùng h·ª£p sau:\n",
    "\n",
    "1. **ƒêi·ªÅu tr·ªã h·ªó tr·ª£ tƒÉng cholesterol m√°u nguy√™n ph√°t v√† r·ªëi lo·∫°n lipid m√°u h·ªón h·ª£p**:\n",
    "   - **Li·ªÅu d√πng**: 10mg/l·∫ßn/ng√†y.\n",
    "   - **Hi·ªáu qu·∫£**: Sau 2 - 4 tu·∫ßn s·ª≠ d·ª•ng, b·ªánh nh√¢n s·∫Ω th·∫•y hi·ªáu qu·∫£ c·ªßa thu·ªëc.\n",
    "   - **L∆∞u √Ω**: Thu·ªëc c·∫ßn ƒë∆∞·ª£c s·ª≠ d·ª•ng duy tr√¨ trong th·ªùi gian d√†i ƒë·ªÉ c√≥ hi·ªáu qu·∫£.\n",
    "\n",
    "2. **ƒêi·ªÅu tr·ªã h·ªó tr·ª£ tƒÉng cholesterol trong m√°u c√≥ t√≠nh gia ƒë√¨nh ƒë·ªìng h·ª£p t·ª≠**:\n",
    "   - **Li·ªÅu d√πng**: 10mg/l·∫ßn/ng√†y (li·ªÅu th∆∞·ªùng d√πng) v√† t·ªëi ƒëa 80mg/l·∫ßn/ng√†y.\n",
    "   - **L∆∞u √Ω**: Li·ªÅu l∆∞·ª£ng c√≥ th·ªÉ ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh t√πy theo c∆° ƒë·ªãa, ti·∫øn tri·ªÉn b·ªánh v√† kh·∫£ nƒÉng dung n·∫°p thu·ªëc c·ªßa ng∆∞·ªùi b·ªánh.\n",
    "\n",
    "3. **R·ªëi lo·∫°n lipid m√°u nghi√™m tr·ªçng ·ªü tr·∫ª t·ª´ 10 - 17 tu·ªïi**:\n",
    "   - **Li·ªÅu d√πng**: 10mg/l·∫ßn/ng√†y, sau ƒë√≥ c√≥ th·ªÉ tƒÉng l√™n 20mg/l·∫ßn/ng√†y t√πy theo t√¨nh tr·∫°ng b·ªánh.\n",
    "   - **Th·ªùi gian ƒëi·ªÅu ch·ªânh li·ªÅu**: Th·ªùi gian ƒëi·ªÅu ch·ªânh li·ªÅu t·ªëi thi·ªÉu l√† 4 tu·∫ßn.\n",
    "\n",
    "**L∆∞u √Ω chung**:\n",
    "- Thu·ªëc ƒë∆∞·ª£c d√πng theo ƒë∆∞·ªùng u·ªëng, u·ªëng khi b·ª•ng ƒë√≥i ho·∫∑c no ƒë·ªÅu ƒë∆∞·ª£c, c√≥ th·ªÉ u·ªëng v√†o b·∫•t c·ª© l√∫c n√†o trong ng√†y.\n",
    "- Kh√¥ng d√πng thu·ªëc Insuact 10mg v·ªõi ng∆∞·ªùi b·ªã qu√° m·∫´n v·ªõi th√†nh ph·∫ßn c·ªßa thu·ªëc, ng∆∞·ªùi c√≥ b·ªánh gan ho·∫°t ƒë·ªông ho·∫∑c tƒÉng transaminase huy·∫øt thanh v√¥ cƒÉn k√©o d√†i, ph·ª• n·ªØ ƒëang mang thai ho·∫∑c nu√¥i con cho b√∫, ph·ª• n·ªØ ƒëang c√≥ √Ω ƒë·ªãnh mang thai.\n",
    "- C·∫ßn ki·ªÉm tra ch·ª©c nƒÉng gan tr∆∞·ªõc v√† trong qu√° tr√¨nh ƒëi·ªÅu tr·ªã.\n",
    "\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
