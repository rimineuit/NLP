{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10281738,"sourceType":"datasetVersion","datasetId":6362577},{"sourceId":10281794,"sourceType":"datasetVersion","datasetId":6362628},{"sourceId":208112,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":177426,"modelId":199733},{"sourceId":208350,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":177632,"modelId":199936}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install rank_bm25\n!pip -q install pyvi\n!pip -q install vncorenlp","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-26T10:19:27.038832Z","iopub.execute_input":"2024-12-26T10:19:27.039155Z","iopub.status.idle":"2024-12-26T10:19:40.812337Z","shell.execute_reply.started":"2024-12-26T10:19:27.039113Z","shell.execute_reply":"2024-12-26T10:19:40.811486Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# from vncorenlp import VnCoreNLP\n# rdrsegmenter = VnCoreNLP(\"/kaggle/input/vncorenlp/other/default/1/VnCoreNLP/VnCoreNLP-1.2.jar\", annotators=\"wseg\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T10:19:40.813668Z","iopub.execute_input":"2024-12-26T10:19:40.813912Z","iopub.status.idle":"2024-12-26T10:19:40.817587Z","shell.execute_reply.started":"2024-12-26T10:19:40.813893Z","shell.execute_reply":"2024-12-26T10:19:40.816626Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install py_vncorenlp\nimport py_vncorenlp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T10:19:40.819125Z","iopub.execute_input":"2024-12-26T10:19:40.819325Z","iopub.status.idle":"2024-12-26T10:19:45.795806Z","shell.execute_reply.started":"2024-12-26T10:19:40.819307Z","shell.execute_reply":"2024-12-26T10:19:45.794622Z"}},"outputs":[{"name":"stdout","text":"Collecting py_vncorenlp\n  Downloading py_vncorenlp-0.1.4.tar.gz (3.9 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting pyjnius (from py_vncorenlp)\n  Downloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nDownloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: py_vncorenlp\n  Building wheel for py_vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for py_vncorenlp: filename=py_vncorenlp-0.1.4-py3-none-any.whl size=4305 sha256=93119fe7cec6ef7276c3603dcdb8ffa177821212eeb486295a4774cfea9d3c18\n  Stored in directory: /root/.cache/pip/wheels/d5/d9/bf/62632cdb007c702a0664091e92a0bb1f18a2fcecbe962d9827\nSuccessfully built py_vncorenlp\nInstalling collected packages: pyjnius, py_vncorenlp\nSuccessfully installed py_vncorenlp-0.1.4 pyjnius-1.6.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir='/kaggle/input/vncorenlp/other/default/1/VnCoreNLP')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T10:19:45.797213Z","iopub.execute_input":"2024-12-26T10:19:45.797482Z","iopub.status.idle":"2024-12-26T10:19:46.472130Z","shell.execute_reply.started":"2024-12-26T10:19:45.797461Z","shell.execute_reply":"2024-12-26T10:19:46.471059Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import os\nimport json\nimport pandas as pd\nfrom tqdm import tqdm\nfrom rank_bm25 import BM25Okapi\nfrom nltk.tokenize import word_tokenize\nimport nltk\nfrom pyvi.ViTokenizer import tokenize","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T10:19:46.473264Z","iopub.execute_input":"2024-12-26T10:19:46.473866Z","iopub.status.idle":"2024-12-26T10:19:47.860394Z","shell.execute_reply.started":"2024-12-26T10:19:46.473833Z","shell.execute_reply":"2024-12-26T10:19:47.859518Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Đường dẫn tới thư mục chứa các file JSON\nqa_folder_path = '/kaggle/input/all-dataset-qa-retrieve/all_dataset_qa_retrieve'\n\n# Danh sách để chứa dữ liệu\nqa_data = []\n\n# Lặp qua tất cả các file trong thư mục và sử dụng tqdm để theo dõi tiến trình\nfor file_name in tqdm(os.listdir(qa_folder_path), desc=\"Reading files\"):\n    \n    if file_name.endswith('.json'):  # Kiểm tra nếu file là file JSON\n        file_path = os.path.join(qa_folder_path, file_name)\n        \n        # Mở và đọc dữ liệu từ file JSON\n        with open(file_path, 'r', encoding='utf-8') as f:\n            qa_file_data = json.load(f)\n            \n            # Lặp qua các câu hỏi và câu trả lời trong dữ liệu\n            for qa in qa_file_data['qa']:\n                qa_data.append({\n                    'question': qa['question'],\n                    'answer': qa['answer'],\n                    'id': qa['id']\n                })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T10:19:47.861344Z","iopub.execute_input":"2024-12-26T10:19:47.861712Z","iopub.status.idle":"2024-12-26T10:19:51.043469Z","shell.execute_reply.started":"2024-12-26T10:19:47.861680Z","shell.execute_reply":"2024-12-26T10:19:51.042618Z"}},"outputs":[{"name":"stderr","text":"Reading files: 100%|██████████| 499/499 [00:02<00:00, 175.93it/s]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Tạo DataFrame từ dữ liệu đã thu thập\nqa_df = pd.DataFrame(qa_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T10:19:51.044401Z","iopub.execute_input":"2024-12-26T10:19:51.044734Z","iopub.status.idle":"2024-12-26T10:19:51.054884Z","shell.execute_reply.started":"2024-12-26T10:19:51.044693Z","shell.execute_reply":"2024-12-26T10:19:51.054153Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"qa_df['tokenized_question'] = qa_df['question'].apply(lambda x: tokenize(x).lower().split())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T10:19:51.055770Z","iopub.execute_input":"2024-12-26T10:19:51.056067Z","iopub.status.idle":"2024-12-26T10:19:51.724916Z","shell.execute_reply.started":"2024-12-26T10:19:51.056036Z","shell.execute_reply":"2024-12-26T10:19:51.724237Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"qa_df['segmented'] = qa_df['question'].apply(lambda x: rdrsegmenter.word_segment(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T10:19:51.727257Z","iopub.execute_input":"2024-12-26T10:19:51.727480Z","iopub.status.idle":"2024-12-26T10:19:54.986882Z","shell.execute_reply.started":"2024-12-26T10:19:51.727461Z","shell.execute_reply":"2024-12-26T10:19:54.985943Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"qa_df['segmented'] =  qa_df['segmented'].apply(lambda x: ' '.join(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T10:19:54.987996Z","iopub.execute_input":"2024-12-26T10:19:54.988235Z","iopub.status.idle":"2024-12-26T10:19:54.993473Z","shell.execute_reply.started":"2024-12-26T10:19:54.988213Z","shell.execute_reply":"2024-12-26T10:19:54.992590Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import pickle\n\n# Load lại bm25 model\nwith open('/kaggle/input/bm25pyvi/other/default/1/bm25_model_pyvi.pkl', 'rb') as f:\n    bm25 = pickle.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T10:19:54.994174Z","iopub.execute_input":"2024-12-26T10:19:54.994416Z","iopub.status.idle":"2024-12-26T10:20:13.380461Z","shell.execute_reply.started":"2024-12-26T10:19:54.994396Z","shell.execute_reply":"2024-12-26T10:20:13.379775Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"chunked_df = pd.read_json('/kaggle/input/df-full-and-chunked/df/chunked_df.json')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T10:20:13.381257Z","iopub.execute_input":"2024-12-26T10:20:13.381527Z","iopub.status.idle":"2024-12-26T10:20:27.579000Z","shell.execute_reply.started":"2024-12-26T10:20:13.381505Z","shell.execute_reply":"2024-12-26T10:20:27.578261Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"chunked_df['segmented'] = chunked_df['content'].apply(lambda x: rdrsegmenter.word_segment(x))","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-26T11:32:08.157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chunked_df['segmented'] = chunked_df['segmented'].apply(lambda x: ' '.join(x))","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-26T11:32:08.157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer\n!pip install -q sentence-transformers\nfrom sentence_transformers import CrossEncoder\n\nMODEL_ID = 'itdainb/PhoRanker'\nMAX_LENGTH = 512\n\nmodel = CrossEncoder(MODEL_ID, max_length=MAX_LENGTH)\ntokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n\ndef truncate_text(text, max_length=256):\n    tokens = tokenizer.encode(text, truncation=True, max_length=max_length, add_special_tokens=True)\n    return tokenizer.decode(tokens, skip_special_tokens=True)\n\nchunked_df['segmented'] = chunked_df['segmented'].apply(lambda x: truncate_text(x, max_length=MAX_LENGTH))","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-26T11:32:08.157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import logging\nfrom transformers import logging as transformers_logging\n\n# Tắt log từ transformers\nlogging.getLogger(\"transformers\").setLevel(logging.ERROR)\ntransformers_logging.set_verbosity_error()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-26T11:32:08.157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport sys\nimport numpy as np\nfrom tqdm import tqdm\nfrom sentence_transformers import CrossEncoder\nfrom contextlib import contextmanager, redirect_stdout, redirect_stderr\n\n@contextmanager\ndef suppress_output():\n    with open(os.devnull, \"w\") as devnull:\n        old_stdout = sys.stdout\n        old_stderr = sys.stderr\n        try:\n            sys.stdout = devnull\n            sys.stderr = devnull\n            yield\n        finally:\n            sys.stdout = old_stdout\n            sys.stderr = old_stderr\n\ndef evaluate_bm25_with_crossencoder_top_k(df, qa_df, bm25, top_k_bm25=200, top_k_values=list(range(1, 101))):\n    results = {f\"Top-{k}\": 0 for k in top_k_values}  # Khởi tạo kết quả đánh giá\n    total_queries = len(qa_df)\n\n    for _, row in tqdm(qa_df.iterrows(), total=total_queries):\n        query = row['tokenized_question']\n        true_id = row['id']\n\n        # Step 1: Dùng BM25 lấy Top-200\n        scores = bm25.get_scores(query)\n        top_indices = scores.argsort()[::-1][:top_k_bm25]  # Top-200 kết quả từ BM25\n        top_candidates = df.iloc[top_indices]\n\n        # Step 2: Tạo input cho CrossEncoder\n        crossencoder_inputs = [[row['segmented'], chunk] for chunk in top_candidates['segmented']]\n\n        # Step 3: Tính điểm bằng CrossEncoder với suppress_output để tắt hiển thị\n        with suppress_output():\n            crossencoder_scores = model.predict(crossencoder_inputs)\n\n        # Step 4: Chọn Top-100 từ CrossEncoder\n        cross_top_indices = np.argsort(crossencoder_scores)[::-1][:len(top_k_values)]\n        top_ids = top_candidates.iloc[cross_top_indices]['id'].tolist()\n\n        # Step 5: Đánh giá cho từng Top-k\n        for k in top_k_values:\n            if true_id in top_ids[:k]:\n                results[f\"Top-{k}\"] += 1\n\n    # Tính độ chính xác cho mỗi Top-k\n    for k in top_k_values:\n        results[f\"Top-{k}\"] /= total_queries\n\n    return results\n\ntop_k_values = list(range(1, 101))  # Top-1 đến Top-100\nevaluation_results = evaluate_bm25_with_crossencoder_top_k(chunked_df, qa_df, bm25, top_k_bm25=200, top_k_values=top_k_values)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-26T11:32:08.157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# In kết quả đánh giá\nfor k, v in evaluation_results.items():\n    print(f\"{k}: {v * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-26T11:32:08.156Z"}},"outputs":[],"execution_count":null}]}